{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-3-12 custom dataset created by Allen LIN\n",
    "import torchvision.transforms as trns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class fingerprintDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.targets = self.img_labels.iloc[:, 1] # label of the dataset\n",
    "        self.data = []\n",
    "        for i in range(len(self.img_labels)):\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[i, 0])\n",
    "            image = cv2.imread(img_path)\n",
    "            self.data.append(image)\n",
    "        self.data = np.array(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = image.cuda()\n",
    "            #unsqueeze(0)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            label = label.cuda()\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "img_path: ../contact-based_fingerprint/first_session/1_1.jpg\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "img_labels = pd.read_csv(\"../contact-based_fingerprint/fingerprint_annotations.csv\")\n",
    "img_dir = \"../contact-based_fingerprint/first_session/\"\n",
    "print(len(img_labels))\n",
    "for i in range(len(img_labels)):\n",
    "    img_path = os.path.join(img_dir, img_labels.iloc[i, 0])\n",
    "    print(f'img_path: {img_path}')\n",
    "    image = cv2.imread(img_path)\n",
    "    data.append(image)\n",
    "    break\n",
    "data = np.array(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 356, 328, 3)\n",
      "train_dataset.targets: [  1   1   1 ... 336 336 336]\n",
      "train_dataset.targets.size: 2016\n",
      "train_dataset.data.size: 706212864\n"
     ]
    }
   ],
   "source": [
    "annotations_file = \"../contact-based_fingerprint/fingerprint_annotations.csv\"\n",
    "img_dir = \"../contact-based_fingerprint/first_session/\"\n",
    "# Normalization for CIFAR\n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                 std=[0.2023, 0.1994, 0.2010])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.ToPILImage(), # to PIL format\n",
    "    transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]\n",
    "\n",
    "transform = transforms.Compose(augmentation)\n",
    "train_dataset = fingerprintDataset(annotations_file, img_dir, transform)\n",
    "print(train_dataset.data.shape)\n",
    "\n",
    "train_labels = np.array(train_dataset.targets)\n",
    "# print(f'train_labels: {train_labels}')\n",
    "# print(f'train_labels.size: {train_labels.size}')\n",
    "num_classes = 336\n",
    "epoch_size = 2016\n",
    "train_idx = np.array(\n",
    "    [np.where(train_labels == i)[0][0:int(epoch_size / num_classes)+1] for i in range(0, num_classes+1)], dtype=object).flatten()\n",
    "train_idx = np.hstack(train_idx)\n",
    "# train_idx = np.arange(start=1, stop=21, step=1)\n",
    "# print(f'train_idx: {train_idx}')\n",
    "# print(f'train_idx.size: {train_idx.size}')\n",
    "train_dataset.targets = train_labels[train_idx]\n",
    "print(f'train_dataset.targets: {train_dataset.targets}')\n",
    "print(f'train_dataset.targets.size: {train_dataset.targets.size}')\n",
    "print(f'train_dataset.data.size: {train_dataset.data.size}')\n",
    "train_dataset.data = train_dataset.data[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "train_labels: [6 9 9 ... 9 1 1]\n",
      "train_idx: [   29    30    35 ... 49963 49971 49997]\n",
      "train_idx.size: 50000\n",
      "train_dataset.targets: [0 0 0 ... 9 9 9]\n",
      "train_dataset.targets.size: 50000\n",
      "train_dataset.data.size: 153600000\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 dataset\n",
    "import torchvision.datasets as datasets\n",
    "import moco.builder\n",
    "import moco.loader\n",
    "datadir = './data'\n",
    "classes = 10\n",
    "epoch_size = 50000\n",
    "# Normalization for CIFAR\n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                 std=[0.2023, 0.1994, 0.2010])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    # transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "]\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=datadir, train=True, download=True,\n",
    "                                 transform=moco.loader.TwoCropsTransform(\n",
    "                                     transforms.Compose(augmentation)))\n",
    "print(train_dataset.data.shape)\n",
    "\n",
    "train_labels = np.array(train_dataset.targets)\n",
    "print(f'train_labels: {train_labels}')\n",
    "num_classes = classes\n",
    "train_idx = np.array(\n",
    "    [np.where(train_labels == i)[0][:int(epoch_size / num_classes)] for i in range(0, num_classes)]).flatten()\n",
    "train_dataset.targets = train_labels[train_idx]\n",
    "train_dataset.data = train_dataset.data[train_idx]\n",
    "print(f'train_idx: {train_idx}')\n",
    "print(f'train_idx.size: {train_idx.size}')\n",
    "print(f'train_dataset.targets: {train_dataset.targets}')\n",
    "print(f'train_dataset.targets.size: {train_dataset.targets.size}')\n",
    "print(f'train_dataset.data.size: {train_dataset.data.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
